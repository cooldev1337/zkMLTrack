# zkMLTrack — Verifiable AI Model Versioning

We are building verifiable ML model versioning: upload an ONNX network, generate a zkML proof with EZKL, and register the result on-chain without revealing the model. This repository captures the prototype we completed during Invisible Garden 2025 Edition, plus the experiments that informed it.

## What is implemented today

- **Automated zkML pipeline (`backend/app.py`).** A Flask service accepts an ONNX model, runs the full EZKL flow (settings → calibration → compile → witness → prove → verify), exports an EVM verifier in Solidity, and can deploy/register it if RPC credentials are provided.
- **Calibrated validation flow.** The backend samples for the validation set are extracted from `backend/iris_test_split.csv`.
- **Optional on-chain registry calls.** When `WEB3_HTTP_PROVIDER`, `WEB3_OPERATOR_KEY`, and `GENERAL_CONTRACT_ADDRESS` are set, the backend compiles the verifier Solidity artifact with solc 0.8.20, deploys it through web3.py.
- **Stylus registry skeleton.** `smartcontracts/src/lib.rs` implements a basic skeleton in  Arbitrum Stylus contract (based on the solidity prototype) to register tasks and track hashed model versions on-chain.
- **Solidity controller experiments.** Contains an initial implementation of the registry contract in Solidity. `pruebas/MainController.sol` is an Ownable + ReentrancyGuard prototype that manages tasks, accepts Merkle-proved samples, and tracks the best verifier accuracy. Missing: Implementation to evaluate verifiers sample-by-sample using the verifier contract generated by EZKL for a task.
- **Frontend scaffolding.** Initial Implementation of `frontend/`. It is a SvelteKit project placeholder upload screens wired to the backend. Missing: Full integration with the backend API and testing.

## Testing Limitations and Trouble we had

- Verifier contracts too large: EZKL verifier contracts were usually 70+ KB  in our tests (Ethereum limit is ~24 KB).

- Circuit generation is heavy: Even small NN models are hard to compile; requires lots of RAM and often crashes locally.

- Outdated tooling: EZKL supports older PyTorch versions and older ONNX opset versions (around opset ≤14) in a stable way.

- Local testing difficult: High memory usage makes compiling circuits and proofs unstable on normal machines.

## Prerequisites

To reproduce the current prototype you will need:

- Python 3.10–3.12
- `pip install -r backend/requirements.txt`
- Rust toolchain + cargo (for Stylus development and solc installs triggered by the backend)
- EZKL CLI installed locally and available on `$PATH`
- Optional: RPC access + funded account if you want to deploy verifiers or call an existing registry

Helpful environment variables: set `ARTIFACTS_ROOT`, `WEB3_HTTP_PROVIDER`, `WEB3_OPERATOR_KEY`, `GENERAL_CONTRACT_ADDRESS`, and `GENERAL_CONTRACT_ABI_PATH` before starting the backend.

## Project structure (current)

```
zkMLTrack/
├── backend/
│   ├── app.py              # Flask server + full EZKL pipeline
│   ├── iris_test_split.csv # Validation dataset used for sampling
│   ├── network.onnx        # Example ONNX model for local tests
│   └── requirements.txt
├── frontend/               # SvelteKit UI scaffold
│   ├── src/                # Components, hooks, routes, translations
│   └── README.md           # Generated sv CLI instructions
├── lib/
│   └── openzeppelin-contracts/ # OZ contracts used by prototypes
├── pruebas/
│   └── MainController.sol  # Solidity prototype for task + accuracy tracking
├── smartcontracts/
│   ├── Cargo.toml
│   └── src/lib.rs          # Stylus registry contract written in Rust
└── readme.md
```

## Component breakdown

### Backend (`backend/`)

The backend is the most complete subsystem:

- `POST /models` accepts `multipart/form-data` with `task_id` and an ONNX file, stores artifacts under `ARTIFACTS_ROOT/<task_id>/`, and runs every EZKL command (`gen_settings`, `calibrate_settings`, `compile_circuit`, `get_srs`, `gen_witness`, `setup`, `prove`, `verify`, `create_evm_verifier`).
- `GET /models/<task_id>/status` exposes pipeline progress saved in `status.json`.
- `GET /models/<task_id>/artifacts/<artifact>` streams generated files (proofs, verifier ABI, etc.).
- When RPC credentials are configured it compiles and deploys the verifier if RPC credentials are configured.
- Contains function to hash the uploaded ONNX model, and calls the configured registry method to persist metadata on-chain, but this is not yet workig end-to-end.

### Frontend (`frontend/`)

The SvelteKit workspace already includes layout, sidebar, navbar, language selector components, and localization scaffolding under `messages/en.json` and `messages/es.json`. The upload experience still needs wiring to the Flask API for model submissions and status polling.

### Smart contracts & experiments

- `smartcontracts/src/lib.rs` implements a Stylus registry contract that lets the owner register tasks and push new hashed model versions, storing timestamps on L2.
- `pruebas/MainController.sol` Solidity program that contains an initial implementation of the registry contract in Solidity. `pruebas/MainController.sol` is an Ownable + ReentrancyGuard prototype that manages tasks, accepts Merkle-proved samples, and tracks the best verifier accuracy. Missing: Implementation to evaluate verifiers sample-by-sample using the verifier contract generated by EZKL for a task.
- `lib/openzeppelin-contracts` to compile the Solidity prototype.


## Future proposal & roadmap

We still want to extend the prototype into a full verifiable model versioning leaderboard. The plan remains:

1. **Dataset anchoring.** Upload reference datasets to decentralized storage (e.g., Filecoin), derive Poseidon-based Merkle roots, and persist them in the Stylus registry instead of local CSV-only storage.
2. **Proof-driven evaluations.** Chainlink VRF (or a Stylus pseudo-random source) will select random samples; participants submit Merkle inclusion proofs plus EZKL proofs given to the verifier contracts for each sample; the Solidity/MainController contract tracks accuracy every time a sample is evaluated until it reaches a certain count. This count is set to avoid too many on-chain calls per model evaluation and to measure performance over a statistically significant number of samples.
3. **Leaderboard UX.** The SvelteKit frontend will display task definitions, submitted verifiers, and their on-chain accuracy, while offering one-click uploads that proxy to the Flask backend per task.
4. **Versioned deployments.** Integrate the Stylus registry in rust, so every successful verifier deployment is tracked in the contract with the models hash and timestamp.


## System Diagram

![Proposal System Diagram](image.png)